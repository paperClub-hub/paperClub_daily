{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: ./model/dbface.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model/dbface.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5c9eb0a48ee9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mextractor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mface_detect\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDetect\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# from extractor import face_records as Records\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\paperClub_hub\\GitHub\\Project\\3_paperClub_Daily\\paperClub_daily\\20220502_人脸识别匹配\\extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mMODEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[0mNET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\paperClub_hub\\GitHub\\Project\\3_paperClub_Daily\\paperClub_daily\\20220502_人脸识别匹配\\extractor.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mdbface\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mdbface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mdbface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./model/dbface.pth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdbface\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\paperClub_hub\\GitHub\\Project\\3_paperClub_Daily\\paperClub_daily\\20220502_人脸识别匹配\\model\\DBFace.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model/dbface.pth'"
     ]
    }
   ],
   "source": [
    "import os,re\n",
    "import cv2\n",
    "import glob,h5py\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from annoy import AnnoyIndex\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from extractor import face_detect as Detect\n",
    "# from extractor import face_records as Records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomat(pil_img):\n",
    "    \"\"\"pil image to cv2 image\"\"\"\n",
    "    img = cv2.cvtColor(np.asarray(pil_img),cv2.COLOR_RGB2BGR)\n",
    "    return img\n",
    "\n",
    "def topil(cv2_img):\n",
    "    \"\"\" pil 转 cv2 bgr\"\"\"\n",
    "    return Image.fromarray(cv2.cvtColor(cv2_img,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "def pil_with_label(pil_img, bbox = [72, 103, 208, 330], label = '胡歌', show_bbox=False):\n",
    "    \"\"\" pil 字体显示文字 , 参考: https://blog.csdn.net/weixin_41735859/article/details/106599903\n",
    "    \"\"\"\n",
    "    \n",
    "    # pil_img = Image.open(img_path)\n",
    "    # bbox = [72, 103, 208, 330] # 边框格式　bbox = [xl, yl, xr, yr]\n",
    "    font = ImageFont.truetype(font=\"E:/1_software/font/simhei.ttf\",  # 设置字体格式及大小\n",
    "                              size=np.floor(1.5e-2 * np.shape(pil_img)[1] + 15).astype('int32'))\n",
    "    \n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    label_size = draw.textsize(label, font) # 获取label长宽\n",
    "    text_origin = np.array([bbox[0], bbox[1] - label_size[1]])  # 设置label起点\n",
    "    \n",
    "    if show_bbox:\n",
    "        # 绘制矩形框，加入label文本\n",
    "        draw.rectangle([bbox[0], bbox[1], bbox[2], bbox[3]],outline='red',width=2) ## bbox\n",
    "    draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill='red') ### label区域\n",
    "    draw.text(text_origin, str(label), fill=(255, 255, 255), font=font)  ### label文字\n",
    "        \n",
    "    del draw\n",
    "    \n",
    "    return pil_img\n",
    "\n",
    "\n",
    "\n",
    "def load_feature_db(dbFile):\n",
    "    h5f = h5py.File(dbFile, 'r')\n",
    "    label_id = h5f['dataset_1'][:]\n",
    "    label_id = [x.decode() for x in label_id]\n",
    "    bbox = h5f['dataset_2'][:]\n",
    "    img_vector = h5f['dataset_3'][:]\n",
    "    h5f.close()\n",
    "\n",
    "    bbox = [x.tolist() for x in bbox]\n",
    "    img_vector = [x for x in img_vector]\n",
    "\n",
    "    df = pd.DataFrame({'img_name': label_id,\n",
    "                       'xyxy':bbox,\n",
    "                       \"img_vector\": img_vector,\n",
    "                       })\n",
    "\n",
    "    # df = None\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_index(db_file, indexFile):\n",
    "    ntree = 30\n",
    "    df = load_feature_db(db_file)\n",
    "    f = len(df['img_vector'][0])  ### 向量长度 512\n",
    "    t = AnnoyIndex(f, metric='euclidean')\n",
    "    for i, vector in enumerate(df['img_vector']):\n",
    "        t.add_item(i, vector)\n",
    "    _ = t.build(ntree)\n",
    "    t.save(indexFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = \"query\"\n",
    "query_src = cv2.imread(\"./images/3.jpg\")\n",
    "query_data = Records(query_id, query_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn2en = {\n",
    "            '其他': \"others\",\n",
    "            '元恒结衣': \"yhjy\",\n",
    "            '周冬雨': \"zdy\",\n",
    "            '易阳天玺': \"yytx\",\n",
    "            '普京':\"pj\",\n",
    "            '杨幂':\"ym\",\n",
    "            '特朗普':\"tlp\",\n",
    "            '王俊凯':\"wjk\",\n",
    "            '王源':\"wy\",\n",
    "            '胡歌':\"hg\"\n",
    "        }\n",
    "\n",
    "en2cn = dict([v,k] for k,v in cn2en.items())\n",
    "\n",
    "\n",
    "DF, INDEXER = None, None\n",
    "dbPath = \"./result/faces.h5\"\n",
    "indexPath = \"./result/faces.ann\"\n",
    "if DF is None:\n",
    "\tDF = load_feature_db(dbPath)\n",
    "if INDEXER is None:\n",
    "\tINDEXER = AnnoyIndex(512, metric='euclidean')\n",
    "\tINDEXER.load(indexPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_map(query_emb, score_cutoff=0.6, num_threshold=10):\n",
    "    def similar_score(a):\n",
    "        def try_divide(x, y, val=0.0):\n",
    "            if y != 0.0:\n",
    "                val = float(x) / y\n",
    "            return val\n",
    "        \n",
    "        v1, v2 = a[0], a[1]\n",
    "        X = float(np.sum(v1 * v2))\n",
    "        Y = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "        return try_divide(X, Y)\n",
    "    \n",
    "    similar_index = INDEXER.get_nns_by_vector(query_emb, int(num_threshold*1.5))\n",
    "    result = DF.iloc[similar_index]\n",
    "    xyxy = result.xyxy.tolist()\n",
    "    names = result.img_name.tolist()\n",
    "\n",
    "    data = [(name, box, score) for name, box, score in \\\n",
    "            zip(names, xyxy, list(map(similar_score, \\\n",
    "                            \t[(query_emb, x) for x in result.img_vector]))) if score > score_cutoff]\n",
    "    \n",
    "    return data[:num_threshold]\n",
    "\n",
    "\n",
    "def show_similar_face(data):\n",
    "\t\n",
    "\tdef plot_box(cv2_bgr, box, label_text):\n",
    "\t\t\"\"\" 结果展示 \"\"\"\n",
    "\t\tpil_img = Image.fromarray(cv2.cvtColor(cv2_bgr, cv2.COLOR_BGR2RGB))\n",
    "\t\tdraw = ImageDraw.Draw(pil_img)\n",
    "\t\tfont = ImageFont.truetype(\"E:/1_software/font/simhei.ttf\",\\\n",
    "\t\t\tsize=np.floor(1.5e-2 * np.shape(cv2_bgr)[1] + 15).astype('int32'))\n",
    "\t\tlabel_size = draw.textsize(label_text, font)\n",
    "\t\t\n",
    "\t\ttext_origin = np.array([box[0] - 2, box[1] - 5 - label_size[1]])  ### 文字起点\n",
    "\t\tdraw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill='red')\n",
    "\t\tdraw.rectangle([box[0], box[1], box[2], box[3]], outline='red', width=4)\n",
    "\t\tdraw.text(text_origin, label_text, fill=(255, 255, 255), font=font)\n",
    "\n",
    "\t\treturn pil_img\n",
    "\n",
    "\tdef pad(image, min_height, min_width):\n",
    "        \n",
    "\t\th, w, _ = image.shape\n",
    "\t\t\"\"\" 图片边填充 \"\"\"\n",
    "\t\tif h < min_height:\n",
    "\t\t\th_pad_top = int((min_height - h) / 2.0)\n",
    "\t\t\th_pad_bottom = min_height - h - h_pad_top\n",
    "\t\telse:\n",
    "\t\t\th_pad_top = 0\n",
    "\t\t\th_pad_bottom = 0\n",
    "\t\tif w < min_width:\n",
    "\t\t\tw_pad_left = int((min_width - w) / 2.0)\n",
    "\t\t\tw_pad_right = min_width - w - w_pad_left\n",
    "\t\telse:\n",
    "\t\t\tw_pad_left = 0\n",
    "\t\t\tw_pad_right = 0\n",
    "\n",
    "\t\treturn cv2.copyMakeBorder(image, h_pad_top,\n",
    "\t\t\t\t\t\t\t\th_pad_bottom,\n",
    "\t\t\t\t\t\t\t\tw_pad_left, w_pad_right,\n",
    "\t\t\t\t\t\t\t\tcv2.BORDER_CONSTANT,\n",
    "\t\t\t\t\t\t\t\tvalue=(255, 255, 255),\n",
    "\t\t\t\t\t\t\t\t)\n",
    "    \n",
    "\tdef show_objs(data):\n",
    "\t\t(W,H ) = data[1]\n",
    "\t\t\n",
    "\t\tprint(data)\n",
    "\t\tif len(data[-1]) > 0:\n",
    "\t\t\tobj_data = data[-1][0] ## [('pj_7.jpg', [266, 182, 395, 348], 0.8574376107492014)]\n",
    "\t\t\tsim_name = obj_data[0]\n",
    "\t\t\tsimilar_imgPath = os.path.join(imgroot, sim_name)\n",
    "\t\t\tlabel_name = os.path.splitext(sim_name)[0].split(\"_\")[0]\n",
    "\t\t\tp_name = en2cn.get(label_name, '未知')\n",
    "\t\t\t\n",
    "\t\t\tbox, score = obj_data[1], obj_data[2]\n",
    "\t\t\tscore = \"%.2f\" % score\n",
    "\t\t\tim = cv2.imread(similar_imgPath)\n",
    "\t\t\tlabel_on = f\"{p_name} {score}\"\n",
    "\t\t\timg = plot_box(im, box, label_on)\n",
    "\t\t\tcv2_img = cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)\n",
    "\t\t\th, w, _  = cv2_img.shape\n",
    "\t\t\tr = min(H, W) / min(h, w)\n",
    "\t\t\tww, hh = int(r * w),int(r * h)\n",
    "\t\t\tcv2_img = pad(cv2.resize(cv2_img, (ww, hh), cv2.INTER_AREA), H, W)\n",
    "\n",
    "\t\t\t# pil_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n",
    "\t\t\t# return  Image.fromarray(pil_img)\n",
    "\n",
    "\t\t\treturn cv2_img\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tcv2_img = np.zeros((H, W, 3), np.uint8)\n",
    "\t\t\tcv2_img.fill(210)\n",
    "\t\t\t# pil_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n",
    "\t\t\treturn cv2_img\n",
    "   \n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\timgroot = \"./data\"\n",
    "\treturn show_objs(data)\n",
    "\n",
    "\n",
    "def face_similar(image_id, image, face_score_cutoff=0.4, iou_cutoff=0.5, \n",
    "                 area_cutoff=1000, max_num_faces=2, similar_cutoff=0.6, max_similar_face=1):\n",
    "\t\"\"\"\n",
    "\t相似人脸检测\n",
    "\t:param image_id:\n",
    "\t:param image:\n",
    "\t:param face_score_cutoff:\n",
    "\t:param iou_cutoff:\n",
    "\t:param area_cutoff:\n",
    "\t:param max_num_faces:\n",
    "\t:param max_similar_face:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tdata = []\n",
    "\th,w = image.shape[:2]\n",
    "\tobjs = Records(image_id, image, face_score_cutoff, iou_cutoff, area_cutoff, max_num_faces)\n",
    "\tfor i, obj in enumerate(objs):\n",
    "\t\timage_id = obj[0]\n",
    "\t\t[w, h] = obj[1]\n",
    "\t\tbox = obj[2]\n",
    "\t\tvec = obj[4]\n",
    "\t\tr = similar_map(vec, score_cutoff=similar_cutoff, num_threshold=max_similar_face)\n",
    "\t\tdata.append([image_id, [w, h], i, box, r, ] )\n",
    "\t\n",
    "\tdel image,image_id, objs\n",
    "\treturn data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = \"query\"\n",
    "query_src = cv2.imread(\"./images/1.png\")\n",
    "query_src = cv2.imread(\"./images/2.jpg\")\n",
    "query_src = cv2.imread(\"./images/3.png\")\n",
    "query_src = cv2.imread(\"./images/4.png\")\n",
    "query_src = cv2.imread(\"./images/6.png\")\n",
    "query_src = cv2.imread(\"./images/8.png\")\n",
    "query_src = cv2.imread(\"./images/9.png\")\n",
    "data = face_similar(query_id, query_src, similar_cutoff=0.7)[0]\n",
    "print(\"查询结果：\")\n",
    "simi_img = show_similar_face(data)\n",
    "query_img = tomat(pil_with_label(topil(query_src), [50, 50, 80, 150], label=\"人脸检索\"))\n",
    "\n",
    "print(query_img.shape, simi_img.shape)\n",
    "topil(np.hstack((query_img, simi_img)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "PyCharm (20220429_image2video)",
   "language": "python",
   "name": "pycharm-15fbff72"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
